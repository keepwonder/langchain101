{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain==0.1.2 openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载环境\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "model = OpenAI(model_name='gpt-3.5-turbo-instruct',temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection error caused failure to post https://api.smith.langchain.com/runs  in LangSmith API. Please confirm your LANGCHAIN_ENDPOINT. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\"))\n",
      "Connection error caused failure to patch https://api.smith.langchain.com/runs/3cc2e459-c91e-40f2-a737-843946fbbbad  in LangSmith API. Please confirm your LANGCHAIN_ENDPOINT. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs/3cc2e459-c91e-40f2-a737-843946fbbbad (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\"))\n"
     ]
    }
   ],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description='question  to set up a joke')\n",
    "    punchline: str = Field(description='answer to resolve the joke')\n",
    "\n",
    "    @validator('setup')\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != '?':\n",
    "            raise ValueError('Badly formed question!')\n",
    "        return field\n",
    "    \n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='Answer the user query.\\n{format_instructions}\\n{query}\\n',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instructions':parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({'query':'Tell me a joke.'})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({'query':'Tell me a joke.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'answer': ''},\n",
       " {'answer': 'Ant'},\n",
       " {'answer': 'Anton'},\n",
       " {'answer': 'Antonie'},\n",
       " {'answer': 'Antonie van'},\n",
       " {'answer': 'Antonie van Lee'},\n",
       " {'answer': 'Antonie van Leeu'},\n",
       " {'answer': 'Antonie van Leeuwen'},\n",
       " {'answer': 'Antonie van Leeuwenho'},\n",
       " {'answer': 'Antonie van Leeuwenhoek'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question} \"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | model | json_parser\n",
    "\n",
    "list(json_chain.stream({'question':'Who invented the microscope'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain.stream({\"query\": \"Tell me a joke.\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV解析器\n",
    "当您希望返回以逗号分隔的项目列表时，可以使用此输出解析器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template='List five {subject}.\\n{format_instructions}',\n",
    "    input_variables=['subject'],\n",
    "    partial_variables={'format_instructions':format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vanilla',\n",
       " 'Chocolate',\n",
       " 'Strawberry',\n",
       " 'Mint Chocolate Chip',\n",
       " 'Cookies and Cream']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'subject':'ice cream flavors'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vanilla']\n",
      "['Chocolate']\n",
      "['Strawberry']\n",
      "['Mint Chocolate Chip']\n",
      "['Cookies and Cream']\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({'subject':'ice cream flavors'}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日期时间解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 0155-08-07T04:41:18.252414Z, 1012-10-24T03:12:14.027451Z, 1861-06-16T19:41:35.903114Z\\n\\nReturn ONLY this string, no other words!\"}, template='Answer ther users question: \\n\\n{question}\\n\\n{format_instructions}')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer ther users question: \n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={'format_instructions':output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | OpenAI() | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-03 18:15:05\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'question':'wher was bitcoin founded?'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 枚举解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class Colors(Enum):\n",
    "    RED = 'red'\n",
    "    GREEN = 'green'\n",
    "    BLUE = 'blue'\n",
    "\n",
    "\n",
    "parser = EnumOutputParser(enum=Colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"What color eyes does this person have?\n",
    "\n",
    "> Person: {person}\n",
    "\n",
    "Instructions: {instructions}\"\"\"\n",
    ").partial(instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | ChatOpenAI() | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Colors.BLUE: 'blue'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'person':'Frank Sinatra'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_query = 'Tell me a joke'\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='Answer the user query.\\n{format_instructions}\\n{query}\\n',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instructions':parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({'query': joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Why'}\n",
      "{'setup': 'Why don'}\n",
      "{'setup': \"Why don't\"}\n",
      "{'setup': \"Why don't scientists\"}\n",
      "{'setup': \"Why don't scientists trust\"}\n",
      "{'setup': \"Why don't scientists trust atoms\"}\n",
      "{'setup': \"Why don't scientists trust atoms?\"}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': ''}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"query\": joke_query}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why don't scientists trust atoms? Because they make up everything!\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI 函数\n",
    "- JsonOutputFunctionsParser\n",
    "- PydanticOutputFunctionsParser\n",
    "- JsonKeyOutputFunctionsParser\n",
    "- PydanticAttrOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description='question to set up a joke')\n",
    "    punchline: str = Field(description='answer to resolve the joke')\n",
    "\n",
    "openai_functions = [convert_pydantic_to_openai_function(Joke)]\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system','You are a helpful assistant'),('user', '{input}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "parser = JsonOutputFunctionsParser()\n",
    "\n",
    "chain = prompt | model.bind(functions=openai_functions) | parser\n",
    "\n",
    "chain.invoke({'input':'Tell me a joke'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Why'}\n",
      "{'setup': 'Why don'}\n",
      "{'setup': \"Why don't\"}\n",
      "{'setup': \"Why don't scientists\"}\n",
      "{'setup': \"Why don't scientists trust\"}\n",
      "{'setup': \"Why don't scientists trust atoms\"}\n",
      "{'setup': \"Why don't scientists trust atoms?\"}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': ''}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything'}\n",
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({'input':'Tell me a joke'}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "class Jokes(BaseModel):\n",
    "    \"\"\"Jokes to tell user\"\"\"\n",
    "    joke: List[Joke]\n",
    "    funniness_level: int\n",
    "\n",
    "\n",
    "parser = JsonKeyOutputFunctionsParser(key_name='joke')\n",
    "\n",
    "openai_functions = [convert_pydantic_to_openai_function(Jokes)]\n",
    "chain = prompt | model.bind(functions=openai_functions) | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'setup': \"Why don't scientists trust atoms?\",\n",
       "  'punchline': 'Because they make up everything!'},\n",
       " {'setup': 'Why did the scarecrow win an award?',\n",
       "  'punchline': 'Because he was outstanding in his field!'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input':'Tell me two jokes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{}]\n",
      "[{'setup': ''}]\n",
      "[{'setup': 'Why'}]\n",
      "[{'setup': 'Why don'}]\n",
      "[{'setup': \"Why don't\"}]\n",
      "[{'setup': \"Why don't scientists\"}]\n",
      "[{'setup': \"Why don't scientists trust\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': ''}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': ''}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': 'Why'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': 'Why don'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': ''}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': 'They'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': 'They don'}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': \"They don't\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': \"They don't have\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': \"They don't have the\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': \"They don't have the guts\"}]\n",
      "[{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}, {'setup': \"Why don't skeletons fight each other?\", 'punchline': \"They don't have the guts!\"}]\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"input\": \"tell me two jokes\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import PydanticOutputFunctionsParser\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description='question to set up a joke')\n",
    "    punchline: str = Field(description='answer to resolve the joke')\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "parser = PydanticOutputFunctionsParser(pydantic_schema=Joke)\n",
    "\n",
    "openai_functions = [convert_pydantic_to_openai_function(Joke)]\n",
    "\n",
    "chain = prompt | model.bind(functions=openai_functions) | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"tell me a joke\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"source used to answer the user's question, should be a website.\",\n",
    "    ),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The capital of France is Paris.',\n",
       " 'source': 'https://en.wikipedia.org/wiki/Paris'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"what's the capital of france?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The capital of France is Paris.', 'source': 'https://en.wikipedia.org/wiki/Paris'}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"what's the capital of france?\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_v0.1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
